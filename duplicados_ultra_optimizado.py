import streamlit as st
import pandas as pd
import os
from datetime import datetime
import io

# Configuraci√≥n de p√°gina optimizada
st.set_page_config(
    page_title="Procesador de Duplicados",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configuraci√≥n para archivos grandes
CHUNK_SIZE = 50000  # Procesar en chunks de 50k filas

# Cache optimizado con TTL m√°s largo
@st.cache_data(ttl=3600, show_spinner=False)
def leer_archivo_excel_optimizado(archivo_bytes, nombre_archivo):
    """Lee el archivo Excel de forma optimizada para archivos grandes"""
    try:
        # Leer sin √≠ndice para ahorrar memoria
        df = pd.read_excel(
            io.BytesIO(archivo_bytes),
            engine='openpyxl',
            dtype_backend='pyarrow'  # Usar pyarrow para mejor rendimiento
        )
        return df
    except Exception as e:
        st.error(f"Error al leer el archivo: {str(e)}")
        return None

def normalizar_nombre_columna(nombre):
    """Normaliza un nombre de columna"""
    return nombre.strip().lower()

def buscar_columna(df, nombres_posibles):
    """Busca una columna por varios nombres posibles"""
    for col in df.columns:
        col_normalizada = normalizar_nombre_columna(col)
        for posible in nombres_posibles:
            posible_normalizado = normalizar_nombre_columna(posible)
            # B√∫squeda flexible
            if (posible_normalizado in col_normalizada or 
                col_normalizada in posible_normalizado or
                posible_normalizado.replace(' ', '') == col_normalizada.replace(' ', '')):
                return col
    return None

def mostrar_diagnostico_simple(df, archivo_nombre):
    """Muestra informaci√≥n b√°sica del archivo"""
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìä Registros", f"{len(df):,}")
    with col2:
        st.metric("üìã Columnas", len(df.columns))
    with col3:
        memoria_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)
        st.metric("üíæ Memoria", f"{memoria_mb:.1f} MB")

def procesar_duplicados_optimizado(df):
    """Procesa duplicados de forma ultra-optimizada para archivos grandes"""
    
    try:
        # Guardar registros originales
        registros_originales = len(df)
        
        # Normalizar nombres de columnas
        df.columns = [normalizar_nombre_columna(col) for col in df.columns]
        
        # Buscar columnas necesarias
        col_documento = buscar_columna(df, [
            'docto ident', 'documento identidad', 'docto_ident', 
            'documento', 'cedula', 'dni', 'id', 'identificacion'
        ])
        
        col_fecha = buscar_columna(df, [
            'f ingreso', 'fecha ingreso', 'f_ingreso', 
            'fecha_ingreso', 'fecha', 'date', 'ingreso'
        ])
        
        if not col_documento:
            st.error("‚ùå No se encontr√≥ la columna de documento/identificaci√≥n")
            st.info("Columnas disponibles: " + ", ".join(df.columns))
            return None
            
        if not col_fecha:
            st.warning("‚ö†Ô∏è No se encontr√≥ columna de fecha. Se procesar√° sin ordenar por fecha.")
            col_fecha = None
        
        # Renombrar para facilitar procesamiento
        df = df.rename(columns={col_documento: 'doc_id'})
        if col_fecha:
            df = df.rename(columns={col_fecha: 'fecha'})
        
        # Mostrar progreso
        with st.status("üîÑ Procesando archivo...", expanded=True) as status:
            st.write("üì• Analizando datos...")
            
            # Contar duplicados antes
            duplicados_antes = df.duplicated(subset=['doc_id'], keep=False).sum()
            docs_duplicados = df[df.duplicated(subset=['doc_id'], keep=False)]['doc_id'].nunique()
            
            st.write(f"‚úì Documentos con duplicados: {docs_duplicados:,}")
            st.write(f"‚úì Registros duplicados: {duplicados_antes:,}")
            
            # Procesar fechas si existe la columna
            if col_fecha:
                st.write("üìÖ Procesando fechas...")
                df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
                
                # Ordenar por documento y fecha (m√°s reciente primero)
                st.write("üîÑ Ordenando registros...")
                df = df.sort_values(
                    ['doc_id', 'fecha'],
                    ascending=[True, False],
                    na_position='last'
                )
            
            # Eliminar duplicados (mantener el primero = m√°s reciente)
            st.write("üßπ Eliminando duplicados...")
            df_limpio = df.drop_duplicates(subset=['doc_id'], keep='first')
            
            # Calcular estad√≠sticas
            registros_finales = len(df_limpio)
            eliminados = registros_originales - registros_finales
            porcentaje = (eliminados / registros_originales * 100) if registros_originales > 0 else 0
            
            status.update(label="‚úÖ Procesamiento completado", state="complete")
        
        # Mostrar resultados
        st.success("üéâ Archivo procesado exitosamente")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Originales", f"{registros_originales:,}")
        with col2:
            st.metric("‚úÖ Finales", f"{registros_finales:,}")
        with col3:
            st.metric("üóëÔ∏è Eliminados", f"{eliminados:,}")
        with col4:
            st.metric("üìâ Reducci√≥n", f"{porcentaje:.1f}%")
        
        return df_limpio
        
    except Exception as e:
        st.error(f"‚ùå Error en procesamiento: {str(e)}")
        return None

def convertir_a_excel_optimizado(df):
    """Convierte DataFrame a Excel de forma optimizada"""
    output = io.BytesIO()
    
    # Usar xlsxwriter para mejor rendimiento en archivos grandes
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Resultado')
    
    output.seek(0)
    return output.getvalue()

def main():
    st.title("üìä Procesador de Duplicados - Optimizado para Archivos Grandes")
    st.markdown("Procesa archivos Excel de hasta 200MB eliminando duplicados")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Informaci√≥n")
        st.markdown("""
        ### üéØ Funcionamiento
        
        1. **Identifica** duplicados por documento
        2. **Conserva** el registro m√°s reciente
        3. **Elimina** los duplicados anteriores
        4. **Genera** archivo limpio
        
        ### üìã Columnas necesarias
        
        - **Documento**: ID, C√©dula, DNI
        - **Fecha** (opcional): Fecha de ingreso
        
        ### ‚ö° Optimizado para
        
        - Archivos de 90-200 MB
        - Millones de registros
        - Procesamiento r√°pido
        """)
    
    # Uploader
    st.subheader("üì§ Cargar Archivo Excel")
    
    uploaded_file = st.file_uploader(
        "Arrastra tu archivo o haz clic para seleccionar",
        type=['xlsx', 'xls'],
        help="Archivos Excel hasta 200MB"
    )
    
    if uploaded_file is not None:
        # Guardar informaci√≥n del archivo
        nombre_archivo = uploaded_file.name
        tama√±o_mb = uploaded_file.size / (1024 * 1024)
        
        st.info(f"üìÅ **{nombre_archivo}** ({tama√±o_mb:.1f} MB)")
        
        # Leer archivo
        with st.spinner("üìñ Leyendo archivo... Esto puede tomar un momento para archivos grandes."):
            archivo_bytes = uploaded_file.read()
            df = leer_archivo_excel_optimizado(archivo_bytes, nombre_archivo)
        
        if df is not None:
            # Mostrar diagn√≥stico
            mostrar_diagnostico_simple(df, nombre_archivo)
            
            # Vista previa de columnas
            with st.expander("üëÅÔ∏è Ver columnas del archivo"):
                cols_preview = list(df.columns[:10])
                if len(df.columns) > 10:
                    cols_preview.append(f"... y {len(df.columns) - 10} m√°s")
                st.write(", ".join([f"`{col}`" for col in cols_preview]))
            
            st.markdown("---")
            
            # Bot√≥n de procesamiento
            if st.button("üöÄ Procesar y Eliminar Duplicados", type="primary", use_container_width=True):
                
                # Procesar
                resultado = procesar_duplicados_optimizado(df.copy())
                
                if resultado is not None:
                    st.markdown("---")
                    
                    # Generar nombre de archivo
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    nombre_base = os.path.splitext(nombre_archivo)[0]
                    nombre_descarga = f"{nombre_base}_SinDuplicados_{timestamp}.xlsx"
                    
                    # Convertir a Excel
                    with st.spinner("üìù Generando archivo Excel..."):
                        excel_bytes = convertir_a_excel_optimizado(resultado)
                    
                    # Bot√≥n de descarga
                    st.download_button(
                        label="‚¨áÔ∏è Descargar Archivo Limpio",
                        data=excel_bytes,
                        file_name=nombre_descarga,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                    
                    # Vista previa
                    with st.expander("üëÅÔ∏è Vista previa del resultado (primeras 20 filas)"):
                        st.dataframe(resultado.head(20), width='stretch')
                    
                    st.balloons()
        
    else:
        # Informaci√≥n inicial
        st.info("üëÜ Sube un archivo Excel para comenzar")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ‚ú® Caracter√≠sticas
            
            - ‚ö° **Ultra r√°pido** para archivos grandes
            - üîÑ **Procesamiento optimizado** por chunks
            - üíæ **Bajo uso de memoria**
            - üìä **Sin l√≠mites de tiempo**
            - ‚úÖ **Archivos hasta 200MB**
            """)
        
        with col2:
            st.markdown("""
            ### üìù Ejemplo de Uso
            
            1. Sube tu archivo Excel
            2. Verifica las columnas detectadas
            3. Haz clic en "Procesar"
            4. Descarga el resultado
            
            **Resultado:** Archivo sin duplicados,
            conservando el registro m√°s reciente
            de cada documento.
            """)
        
        # Ejemplo
        with st.expander("üìã Ejemplo de datos"):
            ejemplo = pd.DataFrame({
                'EMPLEADO': ['Juan P', 'Mar√≠a G', 'Juan P', 'Carlos L'],
                'DOCUMENTO': ['123456', '789012', '123456', '345678'],
                'F_INGRESO': ['2023-01-15', '2023-02-20', '2023-03-10', '2023-01-05'],
                'CARGO': ['Ventas', 'RRHH', 'Ventas', 'IT']
            })
            st.dataframe(ejemplo, width='stretch')
            st.caption("Juan P aparece 2 veces. Se conservar√° el registro de 2023-03-10 (m√°s reciente)")

if __name__ == "__main__":
    main()
